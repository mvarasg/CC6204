{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQ6ZFQewWCZ1"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayJ3FSUaWSgN"
      },
      "source": [
        "# Hyper-parameters \n",
        "input_size = 784\n",
        "num_classes = 10\n",
        "num_epochs = 5\n",
        "batch_size_train = 64\n",
        "batch_size_test = 1000\n",
        "momentum = 0.9\n",
        "log_interval = 100\n",
        "learning_rate=0.001\n",
        "\n",
        "# MNIST dataset \n",
        "train_dataset = torchvision.datasets.MNIST(root='data', \n",
        "                    train=True, \n",
        "                    transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,),(0.5,))]),  \n",
        "                    download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='data', \n",
        "                                          train=False, \n",
        "                                          transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,),(0.5,))]))\n",
        "\n",
        "\n",
        "# Data loader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
        "                                           batch_size=batch_size_train, \n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
        "                                          batch_size=batch_size_test, \n",
        "                                          shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZaybMsk-Lpw"
      },
      "source": [
        "batch = next(enumerate(train_loader))\n",
        "print(batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLqLdQcPy5JF"
      },
      "source": [
        "examples = enumerate(test_loader) \n",
        "\n",
        "batchId, (exampleData, exampleTargets) = next(examples) #Next batch\n",
        "print('Numero de batch: {}'.format(batchId))\n",
        "print(exampleData.shape)\n",
        "print(exampleTargets.shape)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Show the first 6 elements in the batch\n",
        "plt.figure()\n",
        "for i in range(16):\n",
        "  plt.subplot(4, 4, i+1)\n",
        "  plt.tight_layout()\n",
        "  plt.imshow(exampleData[i][0], cmap='gray', interpolation='none')\n",
        "  plt.title('Groundtruth: {}'.format(exampleTargets[i]))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnk3XXO-WXJ0"
      },
      "source": [
        "#Create the neural network\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
        "    self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
        "    self.conv3 = nn.Conv2d(32, 64, kernel_size=3)\n",
        "    self.fc1 = nn.Linear(5*5*64, 256)\n",
        "    self.fc2 = nn.Linear(256,10)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    # x es 28 x 28\n",
        "    x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "    x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
        "    x = F.relu(self.conv3(x))\n",
        "    x = x.view(-1, 5*5*64)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "    return F.log_softmax(x)\n",
        "  \n",
        "network = Net()\n",
        "optimizer = optim.SGD(network.parameters(), lr=learning_rate, momentum=momentum)\n",
        "\n",
        "network = network.to(device)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hX18k41fVXy"
      },
      "source": [
        "import torchsummary as ts\n",
        "\n",
        "print(network)\n",
        "ts.summary(network.to(device), (1, 28, 28), device='cuda')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_tiT29LX12_"
      },
      "source": [
        "train_losses = []\n",
        "train_counter = []\n",
        "test_losses = []\n",
        "\n",
        "test_counter = [i*len(train_loader.dataset) for i in range(num_epochs+1)]\n",
        "\n",
        "#Function to train one epoch\n",
        "def train(network, optimizer,  epoch):\n",
        "  network.train() #Modo entrenamiento\n",
        "  for batchId, (data, target) in enumerate(train_loader): #Iterate over batches\n",
        "    data = data.to(device)\n",
        "    target = target.to(device)\n",
        "    \n",
        "    #Feedforward pass\n",
        "    optimizer.zero_grad()\n",
        "    output = network(data)\n",
        "    loss = F.nll_loss(output, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    if batchId % log_interval == 0:\n",
        "      print('Train epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch, batchId*len(data), len(train_loader.dataset), 100.*batchId/len(train_loader), loss.item()))\n",
        "      train_losses.append(loss.item())\n",
        "      train_counter.append((batchId*64) + ((epoch-1)*len(train_loader.dataset)))\n",
        "      torch.save(network.state_dict(),'model.pth')\n",
        "      torch.save(optimizer.state_dict(), 'optimizer.pth')\n",
        "      \n",
        "\n",
        "#Testing\n",
        "def test(network):\n",
        "  network.eval() #Test mode\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "      data = data.to(device)\n",
        "      target = target.to(device)\n",
        "      output = network(data)\n",
        "      test_loss += F.nll_loss(output, target, size_average=False).item()\n",
        "      pred = output.data.max(1, keepdim=True)[1]\n",
        "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
        "  length = len(test_loader.dataset)\n",
        "  test_loss /= length\n",
        "  test_losses.append(test_loss)\n",
        "  print('\\nTest set: Avg. Loss: {:.4f}, Accuracy: {}/{} ({:.0f}%), Error: {:.3f}% \\n'.format(test_loss, correct, len(test_loader.dataset), 100.*correct/len(test_loader.dataset), 100.*(length-correct)/length))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7X_eHKcYFSZ"
      },
      "source": [
        "test(network)\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "  train(network, optimizer, epoch)\n",
        "  test(network)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L86v0cdZeEoA"
      },
      "source": [
        "plt.figure()\n",
        "plt.plot(train_counter, train_losses, color='blue')\n",
        "plt.scatter(test_counter, test_losses, color='red')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZo3uXUCVBLP"
      },
      "source": [
        "with torch.no_grad():\n",
        "  output = network(exampleData.to(device))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFOOO7bjVR1Y"
      },
      "source": [
        "fig = plt.figure()\n",
        "for i in range(6):\n",
        "  plt.subplot(2,3,i+1)\n",
        "  plt.tight_layout()\n",
        "  plt.imshow(exampleData[i][0], cmap='gray', interpolation='none')\n",
        "  plt.title(\"Prediction: {}\".format(\n",
        "    output.data.max(1, keepdim=True)[1][i].item()))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltoqUiU8VbBn"
      },
      "source": [
        "continued_network = Net()\n",
        "network_state_dict = torch.load('model.pth')\n",
        "continued_network.load_state_dict(network_state_dict)\n",
        "continued_network = continued_network.to(device)\n",
        "\n",
        "continued_optimizer = optim.SGD(continued_network.parameters(), lr=0.0005, momentum=momentum)\n",
        "optimizer_state_dict=torch.load('optimizer.pth')\n",
        "continued_optimizer.load_state_dict(optimizer_state_dict)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BxNoMWMY7x8"
      },
      "source": [
        "for i in range(6, 10):\n",
        "  test_counter.append(i*len(train_loader.dataset))\n",
        "  train(continued_network, continued_optimizer, i)\n",
        "  test(continued_network)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEJTGAaMZJ_a"
      },
      "source": [
        "print(len(test_counter))\n",
        "print(len(test_losses))\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(train_counter, train_losses, color='blue')\n",
        "plt.scatter(test_counter, test_losses, color='red')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCIZBZQpaMgz"
      },
      "source": [
        "print(network)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfEhoio9HLro"
      },
      "source": [
        "#Function to get predictions over a dataset\n",
        "\n",
        "def get_predictions(model, iterator, device):\n",
        "\n",
        "    #For prediction, we also deactivate training features\n",
        "    model.eval()\n",
        "\n",
        "    images = []\n",
        "    labels = []\n",
        "    probs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for (data, target) in iterator:\n",
        "            data = data.to(device)\n",
        "            y_pred = model(data)\n",
        "\n",
        "            #Remember that our network does not apply the softmax\n",
        "            #We have to do it explicitly for prediction\n",
        "            #y_prob = F.softmax(y_pred, dim = -1)\n",
        "            top_pred = y_pred.argmax(1, keepdim = True)\n",
        "\n",
        "            #We store the images, their labels and the pdf of each sample\n",
        "            #images.append(x.cpu())\n",
        "            labels.append(target.cpu())\n",
        "            probs.append(y_pred.cpu())\n",
        "\n",
        "    #images = torch.cat(images, dim = 0)\n",
        "    labels = torch.cat(labels, dim = 0)\n",
        "    probs = torch.cat(probs, dim = 0)\n",
        "\n",
        "    return labels, probs"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUc2r_wxEHu2"
      },
      "source": [
        "#Comute predictions and the label with the maximum probability\n",
        "labels, probs = get_predictions(continued_network, test_loader, device)\n",
        "\n",
        "pred_labels = torch.argmax(probs, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1LiQFyaEcHn"
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "#Plot a confussion matrix\n",
        "def plot_confusion_matrix(labels, pred_labels):\n",
        "    \n",
        "    fig = plt.figure(figsize = (10, 10));\n",
        "    ax = fig.add_subplot(1, 1, 1);\n",
        "    cm = metrics.confusion_matrix(labels, pred_labels);\n",
        "    cm = metrics.ConfusionMatrixDisplay(cm);\n",
        "    cm.plot(values_format = 'd', cmap = 'Blues', ax = ax)\n",
        "\n",
        "plot_confusion_matrix(labels, pred_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oB0dHscIEomb"
      },
      "source": [
        "print(metrics.classification_report(labels, pred_labels, digits=6))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nwaafV0qEt7Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}